{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks are another kind of neural network. They're especially good at dealing with sequential data. At each step of the sequence the network takes two inputs: the encoding of the appropriate element of the sequence, and the hidden state of the network from the previous element. This allows sequential relationships to have bearing on the output of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks are great for a wide variety of tasks, and especially for \"sequence to representation\" and \"sequence to sequence\" tasks. A \"sequence to representation\" task might be something like producing a sentiment score for a sentence. A \"sequence to sequence\" task might be producing a new sentence given an old one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read the data for the sequence-to-sequence game of thrones model.\n",
    "\n",
    "Here, I've compiled a folder with transcripts of each game of thrones episode. I'll read the scripts into a list of all the lines, and then I'll embed the scripts as a sequence of one-hot vectors for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scripts_path = os.path.abspath('//Users/jeremiahsafe/Documents/Data/GOTScripts')\n",
    "script_files = [os.path.join(scripts_path, x) for x in os.listdir(scripts_path)]\n",
    "\n",
    "got_lines = []\n",
    "alphabet = set(['<s>', '</s>'])\n",
    "for sf in script_files:\n",
    "    with open(sf, 'r') as fp:\n",
    "        for line in fp:\n",
    "            for c in line.lower():\n",
    "                alphabet.add(c)\n",
    "            got_lines.append(line.lower())\n",
    "\n",
    "class Embedder(object):\n",
    "    \n",
    "    def __init__(self, alphabet):\n",
    "        self.alphabet = alphabet\n",
    "        self.character_embedding = {}\n",
    "        self.alphabet_to_idx = {}\n",
    "        self.idx_to_alphabet = {}\n",
    "        \n",
    "        for i, glyph in enumerate(self.alphabet):\n",
    "            self.alphabet_to_idx[glyph] = i\n",
    "            self.idx_to_alphabet[i] = glyph\n",
    "        \n",
    "        for i, glyph in enumerate(self.alphabet):\n",
    "            emb = torch.zeros(1, len(self.alphabet))\n",
    "            emb[0][self.alphabet_to_idx[glyph]] = 1\n",
    "            self.character_embedding[glyph] = emb\n",
    "            \n",
    "    def embed_sentence(self, sentence):\n",
    "        embs = list(map(lambda x: self.character_embedding[x], sentence))\n",
    "        return torch.cat(embs, 0)\n",
    "    \n",
    "    def unembed_scores(self, scores):\n",
    "        _, idxs = torch.max(scores, dim=1)\n",
    "        res = []\n",
    "        for i in idxs:\n",
    "            res.append(self.idx_to_alphabet[int(i)])\n",
    "        return res\n",
    "        \n",
    "embedder = Embedder(alphabet)  \n",
    "sequences = []\n",
    "for line in got_lines:\n",
    "    tagged_line = ['<s>'] + list(line) + ['</s>']\n",
    "    sequences.append(embedder.embed_sentence(tagged_line))\n",
    "    \n",
    "sequence_pairs = []\n",
    "for seq in sequences:\n",
    "    sequence_pairs.append((seq, seq[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Language Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, alphabet_size, hidden_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(alphabet_size, hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, alphabet_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = sentence.view(len(sentence), 1, -1)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        to_char = self.fc1(lstm_out.view(len(sentence), -1))\n",
    "        char_scores = self.softmax(to_char)\n",
    "        return char_scores\n",
    "\n",
    "k = len(alphabet)\n",
    "model = LSTM(k, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x, target in sequence_pairs[:10]:\n",
    "    print(len(x), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = .1)\n",
    "\n",
    "for n in range(5):\n",
    "    running_loss = 0\n",
    "    for i, (x, target) in enumerate(sequence_pairs[:10]):\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(x.view(len(x), -1))[:-1]\n",
    "        loss = loss_fn(scores, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i & 500 == 499:\n",
    "            print(\"[{} {}] loss = {}\".format(n+1, i+1, running_loss))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py3]",
   "language": "python",
   "name": "Python [py3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
